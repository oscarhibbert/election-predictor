{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports using Sklearn make shortcut functions\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print current time\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports data\n",
    "data = pd.read_csv('../raw_data/1988_to_2024_combined_clean_polling_and_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renames randmom PERCENTAGE COLUMN - FIX IN DATA CLEANING\n",
    "data.rename(columns={'OTH_PERCENTAGE': 'OTH_ACT'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "data['enddate'] = pd.to_datetime(data['enddate'])\n",
    "data['next_elec_date'] = pd.to_datetime(data['next_elec_date'])\n",
    "data['startdate'] = pd.to_datetime(data['startdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle numerical transformer\n",
    "num_columns_selector = ['samplesize', 'months_to_elec_weight']\n",
    "num_transformer = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical transformer\n",
    "cat_columns_selector = ['rating']\n",
    "cat_transformer = make_pipeline(OrdinalEncoder(categories = [['F','F+','E-','E','E+','D-','D','D+','C-','C','C+','B-','B','B+','A-']]),MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoder for party_in_power\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the preprocessing pipeline\n",
    "preproc_pipeline = make_column_transformer(\n",
    "    (num_transformer, num_columns_selector),\n",
    "    (cat_transformer, cat_columns_selector),\n",
    "    (ohe,['party_in_power']),\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "next_elec_date\n",
       "2015-05-07    1930\n",
       "2024-07-04    1362\n",
       "2010-05-06     584\n",
       "1992-04-09     453\n",
       "2019-12-12     440\n",
       "1997-05-01     338\n",
       "2017-06-08     254\n",
       "2001-06-07     213\n",
       "2005-05-05      98\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['next_elec_date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define election dates\n",
    "election_date_2019 = datetime.strptime('2019-12-12', '%Y-%m-%d')\n",
    "cutoff_date = election_date_2019 - timedelta(days=84)\n",
    "prediction_date = election_date_2019 - timedelta(days=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "data_train = data[data['startdate'] > '2003-12-31']\n",
    "data_train = data_train[data_train['startdate'] < cutoff_date]\n",
    "data_test_1 = data[(data['startdate'] >= cutoff_date) & (data['startdate'] < prediction_date)]\n",
    "data_test = data_test_1[data_test_1['next_elec_date'] == election_date_2019]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit transform preprocessing pipeline to data_train\n",
    "data_train_processed = preproc_pipeline.fit_transform(data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform preprocessing pipeline to data_test\n",
    "data_test_processed = preproc_pipeline.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature names make sense for data_train\n",
    "data_train_processed = pd.DataFrame(\n",
    "    data_train_processed, columns=preproc_pipeline.get_feature_names_out()\n",
    ")\n",
    "\n",
    "# Check feature names make sense for data_test\n",
    "data_test_processed = pd.DataFrame(\n",
    "    data_test_processed, columns=preproc_pipeline.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['samplesize', 'months_to_elec_weight', 'rating',\n",
       "       'party_in_power_Conservative', 'party_in_power_Labour', 'Unnamed: 0',\n",
       "       'startdate', 'enddate', 'pollster', 'next_elec_date', 'days_to_elec',\n",
       "       'months_to_elec', 'poll_length', 'CON_FC', 'LAB_FC', 'LIB_FC', 'BRX_FC',\n",
       "       'GRE_FC', 'OTH_FC', 'PLC_FC', 'SNP_FC', 'UKI_FC', 'CON_ACT', 'LAB_ACT',\n",
       "       'LIB_ACT', 'BRX_ACT', 'GRE_ACT', 'PLC_ACT', 'SNP_ACT', 'UKI_ACT',\n",
       "       'OTH_ACT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our X by dropping irrelevant and y columns\n",
    "\n",
    "X_train = data_train_processed.drop(columns=['startdate', 'enddate', 'pollster', 'Unnamed: 0', 'next_elec_date', 'days_to_elec', 'months_to_elec', 'party_in_power_Labour', 'LAB_ACT', 'CON_ACT', 'LIB_ACT', 'GRE_ACT', 'BRX_ACT', 'SNP_ACT', 'UKI_ACT', 'PLC_ACT', 'OTH_ACT'])\n",
    "X_test = data_test_processed.drop(columns=['startdate', 'enddate', 'pollster', 'Unnamed: 0', 'next_elec_date', 'days_to_elec', 'months_to_elec', 'party_in_power_Labour', 'LAB_ACT', 'CON_ACT', 'LIB_ACT', 'GRE_ACT', 'BRX_ACT', 'SNP_ACT', 'UKI_ACT', 'PLC_ACT', 'OTH_ACT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our target matrix\n",
    "y_train = data_train_processed[['next_elec_date', 'LAB_ACT', 'CON_ACT', 'LIB_ACT', 'GRE_ACT', 'BRX_ACT', 'SNP_ACT', 'UKI_ACT', 'PLC_ACT', 'OTH_ACT']]\n",
    "y_test = data_test_processed[['next_elec_date', 'LAB_ACT', 'CON_ACT', 'LIB_ACT', 'GRE_ACT', 'BRX_ACT', 'SNP_ACT', 'UKI_ACT', 'PLC_ACT', 'OTH_ACT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops y_train actuals where the actual is the actual result we are trying to predict, replaces with NaNs\n",
    "y_train.loc[y_train['next_elec_date'] == '2019-12-12',\n",
    "         ['LAB_ACT', 'CON_ACT', 'LIB_ACT', 'GRE_ACT', 'BRX_ACT', 'SNP_ACT', 'UKI_ACT', 'PLC_ACT', 'OTH_ACT']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samplesize</th>\n",
       "      <th>months_to_elec_weight</th>\n",
       "      <th>rating</th>\n",
       "      <th>party_in_power_Conservative</th>\n",
       "      <th>poll_length</th>\n",
       "      <th>CON_FC</th>\n",
       "      <th>LAB_FC</th>\n",
       "      <th>LIB_FC</th>\n",
       "      <th>BRX_FC</th>\n",
       "      <th>GRE_FC</th>\n",
       "      <th>OTH_FC</th>\n",
       "      <th>PLC_FC</th>\n",
       "      <th>SNP_FC</th>\n",
       "      <th>UKI_FC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "      <td>60.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>16.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0.037283</td>\n",
       "      <td>0.831387</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>27</td>\n",
       "      <td>9.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        samplesize  months_to_elec_weight  rating  \\\n",
       "count    60.000000              60.000000    60.0   \n",
       "unique   51.000000               3.000000     4.0   \n",
       "top       0.037283               0.831387     1.0   \n",
       "freq      3.000000              30.000000    37.0   \n",
       "\n",
       "        party_in_power_Conservative  poll_length  CON_FC  LAB_FC  LIB_FC  \\\n",
       "count                          60.0           60   60.00   60.00   60.00   \n",
       "unique                          1.0            8   16.00   13.00   12.00   \n",
       "top                             1.0            1    0.37    0.29    0.15   \n",
       "freq                           60.0           27    9.00   12.00   11.00   \n",
       "\n",
       "        BRX_FC  GRE_FC  OTH_FC  PLC_FC  SNP_FC  UKI_FC  \n",
       "count    56.00   60.00    60.0   60.00   60.00    39.0  \n",
       "unique   13.00    9.00     5.0    2.00    4.00     3.0  \n",
       "top       0.12    0.03     0.0    0.01    0.04     0.0  \n",
       "freq     11.00   23.00    25.0   36.00   35.00    24.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "samplesize                     0.039575\n",
       "months_to_elec_weight          0.776239\n",
       "rating                         0.904762\n",
       "party_in_power_Conservative         1.0\n",
       "poll_length                         2.2\n",
       "CON_FC                         0.379167\n",
       "LAB_FC                           0.2665\n",
       "LIB_FC                         0.168333\n",
       "BRX_FC                         0.092321\n",
       "GRE_FC                         0.041833\n",
       "OTH_FC                         0.009333\n",
       "PLC_FC                            0.006\n",
       "SNP_FC                           0.0375\n",
       "UKI_FC                         0.004615\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates average median value of X_test\n",
    "averages = X_test.mean()\n",
    "averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates imputation values for y_train to impute over actuals we are trying to predict\n",
    "imputation_values = {\n",
    "    'CON_ACT': averages['CON_FC'],\n",
    "    'LAB_ACT': averages['LAB_FC'],\n",
    "    'LIB_ACT': averages['LIB_FC'],\n",
    "    'BRX_ACT': averages['BRX_FC'],\n",
    "    'GRE_ACT': averages['GRE_FC'],\n",
    "    'OTH_ACT': averages['OTH_FC'],\n",
    "    'PLC_ACT': averages['PLC_FC'],\n",
    "    'SNP_ACT': averages['SNP_FC'],\n",
    "    'UKI_ACT': averages['UKI_FC']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kb/jn3km5pj6lnd7dfkgljcjy300000gn/T/ipykernel_29291/3014033841.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y_train = y_train.fillna(value=imputation_values)\n"
     ]
    }
   ],
   "source": [
    "# Applies imputation values to y_train\n",
    "y_train = y_train.fillna(value=imputation_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model for each party\n",
    "models = {}\n",
    "parties = ['CON', 'LAB', 'LIB', 'BRX', 'GRE', 'SNP', 'UKI', 'PLC', 'OTH']\n",
    "for party in parties:\n",
    "    models[party] = XGBRegressor(\n",
    "        learning_rate=0.3, n_estimators=300, max_depth=3, subsample=0.7,\n",
    "        objective='reg:squarederror', nthread=-1, enable_categorical=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "X_train_matrix = np.array(X_train)\n",
    "for party in parties:\n",
    "    models[party].fit(X_train_matrix, y_train[f'{party}_ACT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate feature importance for each party model\n",
    "# for i, x in enumerate(X_train.columns):\n",
    "#     print(i, ' : ', x)\n",
    "# for party in parties:\n",
    "#     plt.bar(range(len(models[party].feature_importances_)), models[party].feature_importances_)\n",
    "#     plt.xlabel(party)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate model performance with cross validation\n",
    "# cv_scores = {}\n",
    "# for party in parties:\n",
    "#     cv_scores[party] = cross_val_score(models[party], X_train_matrix, y_train[f'{party}_ACT']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_2019 = {\n",
    "    \"CON\": 0.4378,  # Conservative Party\n",
    "    \"LAB\": 0.3267,  # Labour Party\n",
    "    \"LIB\": 0.1164,  # Liberal Democrats\n",
    "    \"BRX\": 0.0200,  # Brexit Party\n",
    "    \"GRE\": 0.0254,  # Green Party\n",
    "    \"SNP\": 0.0379,  # Scottish National Party\n",
    "    \"UKI\": 0.0000,  # UK Independence Party\n",
    "    \"PLC\": 0.0051,  # Plaid Cymru\n",
    "    \"OTH\": 0.0307   # Other parties\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "X_test_matrix = np.array(X_test)\n",
    "mean_predictions = {}\n",
    "for party in parties:\n",
    "    mean_predictions[party] = models[party].predict(X_test_matrix).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "samplesize                     0.039575\n",
       "months_to_elec_weight          0.776239\n",
       "rating                         0.904762\n",
       "party_in_power_Conservative         1.0\n",
       "poll_length                         2.2\n",
       "CON_FC                         0.379167\n",
       "LAB_FC                           0.2665\n",
       "LIB_FC                         0.168333\n",
       "BRX_FC                         0.092321\n",
       "GRE_FC                         0.041833\n",
       "OTH_FC                         0.009333\n",
       "PLC_FC                            0.006\n",
       "SNP_FC                           0.0375\n",
       "UKI_FC                         0.004615\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 mean prediction for CON: 0.4005642235279083\n",
      "2019 actual result for CON  : 0.4378\n",
      "2019 mean prediction for LAB: 0.29026132822036743\n",
      "2019 actual result for LAB  : 0.3267\n",
      "2019 mean prediction for LIB: 0.1591961830854416\n",
      "2019 actual result for LIB  : 0.1164\n",
      "2019 mean prediction for BRX: 0.0629538893699646\n",
      "2019 actual result for BRX  : 0.02\n",
      "2019 mean prediction for GRE: 0.03725437819957733\n",
      "2019 actual result for GRE  : 0.0254\n",
      "2019 mean prediction for SNP: 0.0359082855284214\n",
      "2019 actual result for SNP  : 0.0379\n",
      "2019 mean prediction for UKI: 0.010248980484902859\n",
      "2019 actual result for UKI  : 0.0\n",
      "2019 mean prediction for PLC: 0.005723768379539251\n",
      "2019 actual result for PLC  : 0.0051\n",
      "2019 mean prediction for OTH: 0.013436107896268368\n",
      "2019 actual result for OTH  : 0.0307\n"
     ]
    }
   ],
   "source": [
    "# Print mean predictions\n",
    "for party in parties:\n",
    "    print(f\"2019 mean prediction for {party}: {mean_predictions[party]}\")\n",
    "    print(f\"2019 actual result for {party}  : {actuals_2019[party]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37916666666666676"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averages['CON_FC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate last five polls\n",
    "last_predictions = {}\n",
    "for party in parties:\n",
    "    last_predictions[party] = models[party].predict(X_test_matrix)[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 last prediction for CON: 0.39079517126083374\n",
      "2019 actual result for CON  : 0.4378\n",
      "2019 last prediction for LAB: 0.30251994729042053\n",
      "2019 actual result for LAB  : 0.3267\n",
      "2019 last prediction for LIB: 0.15667665004730225\n",
      "2019 actual result for LIB  : 0.1164\n",
      "2019 last prediction for BRX: 0.06764575839042664\n",
      "2019 actual result for BRX  : 0.02\n",
      "2019 last prediction for GRE: 0.03048955835402012\n",
      "2019 actual result for GRE  : 0.0254\n",
      "2019 last prediction for SNP: 0.03536443039774895\n",
      "2019 actual result for SNP  : 0.0379\n",
      "2019 last prediction for UKI: 0.009905876591801643\n",
      "2019 actual result for UKI  : 0.0\n",
      "2019 last prediction for PLC: 0.005601013079285622\n",
      "2019 actual result for PLC  : 0.0051\n",
      "2019 last prediction for OTH: 0.012515529990196228\n",
      "2019 actual result for OTH  : 0.0307\n"
     ]
    }
   ],
   "source": [
    "# Print mean of predictions\n",
    "for party in parties:\n",
    "    print(f\"2019 last prediction for {party}: {last_predictions[party].mean()}\")\n",
    "    print(f\"2019 actual result for {party}  : {actuals_2019[party]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "election_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

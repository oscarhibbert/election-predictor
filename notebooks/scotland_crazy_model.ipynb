{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports using Sklearn make shortcut functions\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print current time\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports data\n",
    "data = pd.read_csv('../processed_data/scotland_polling_results_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1        0\n",
       "Unnamed: 0          0\n",
       "startdate           0\n",
       "enddate             0\n",
       "pollster            0\n",
       "samplesize          0\n",
       "rating              0\n",
       "next_elec_date      0\n",
       "days_to_elec        0\n",
       "BRX_FC            189\n",
       "CON_FC              0\n",
       "GRE_FC             64\n",
       "LAB_FC              0\n",
       "LIB_FC              0\n",
       "OTH_FC             36\n",
       "SNP_FC              0\n",
       "OTH.1              36\n",
       "UKI_FC            132\n",
       "SNP_ACT           110\n",
       "LAB_ACT           110\n",
       "LIB_ACT           110\n",
       "CON_ACT           110\n",
       "UKI_ACT           110\n",
       "GRE_ACT           110\n",
       "BRX_ACT           110\n",
       "OTH_PERCENTAGE    110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "data['enddate'] = pd.to_datetime(data['enddate'])\n",
    "data['next_elec_date'] = pd.to_datetime(data['next_elec_date'])\n",
    "data['startdate'] = pd.to_datetime(data['startdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle numerical transformer\n",
    "num_columns_selector = ['samplesize', 'days_to_elec']\n",
    "num_transformer = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical transformer\n",
    "cat_columns_selector = ['rating']\n",
    "cat_transformer = make_pipeline(OrdinalEncoder(categories = [['F','F+','E-','E','E+','D-','D','D+','C-','C','C+','B-','B','B+','A-']]),MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One-hot encoder for party_in_power\n",
    "# ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the preprocessing pipeline\n",
    "preproc_pipeline = make_column_transformer(\n",
    "    (num_transformer, num_columns_selector),\n",
    "    (cat_transformer, cat_columns_selector),\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "next_elec_date\n",
       "2024-07-04    110\n",
       "2015-05-07     52\n",
       "2019-12-12     38\n",
       "2017-06-08     17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['next_elec_date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'OTH_PERCENTAGE':'OTH_ACT'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define election dates\n",
    "election_date = datetime.strptime('2019-12-12', '%Y-%m-%d')\n",
    "cutoff_date = election_date - timedelta(days=100)\n",
    "prediction_date = election_date - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "data_train = data[data['startdate'] > '2003-12-31']\n",
    "data_train = data_train[data_train['startdate'] < cutoff_date]\n",
    "data_test_1 = data[(data['startdate'] >= cutoff_date) & (data['startdate'] < prediction_date)]\n",
    "data_test = data_test_1[data_test_1['next_elec_date'] == election_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit transform preprocessing pipeline to data_train\n",
    "data_train_processed = preproc_pipeline.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform preprocessing pipeline to data_test\n",
    "data_test_processed = preproc_pipeline.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature names make sense for data_train\n",
    "data_train_processed = pd.DataFrame(\n",
    "    data_train_processed, columns=preproc_pipeline.get_feature_names_out()\n",
    ")\n",
    "\n",
    "# Check feature names make sense for data_test\n",
    "data_test_processed = pd.DataFrame(\n",
    "    data_test_processed, columns=preproc_pipeline.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our X by dropping irrelevant and y columns\n",
    "X_train = data_train_processed.drop(columns=['startdate', 'enddate', 'pollster', 'Unnamed: 0', 'next_elec_date', 'days_to_elec', 'LAB_ACT', 'CON_ACT', 'LIB_ACT', 'GRE_ACT', 'BRX_ACT', 'SNP_ACT', 'UKI_ACT','OTH_ACT'])\n",
    "X_test = data_test_processed.drop(columns=['startdate', 'enddate', 'pollster', 'Unnamed: 0', 'next_elec_date', 'days_to_elec', 'LAB_ACT', 'CON_ACT', 'LIB_ACT', 'GRE_ACT', 'BRX_ACT', 'SNP_ACT', 'UKI_ACT','OTH_ACT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build our target matrix\n",
    "y_train = data_train_processed[['next_elec_date', 'LAB_ACT', 'CON_ACT', 'LIB_ACT', 'GRE_ACT', 'BRX_ACT', 'SNP_ACT', 'UKI_ACT']]\n",
    "y_test = data_test_processed[['next_elec_date', 'LAB_ACT', 'CON_ACT', 'LIB_ACT', 'GRE_ACT', 'BRX_ACT', 'SNP_ACT', 'UKI_ACT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops y_train actuals where the actual is the actual result we are trying to predict, replaces with NaNs\n",
    "y_train.loc[y_train['next_elec_date'] == '2019-12-12',\n",
    "         ['LAB_ACT', 'CON_ACT', 'LIB_ACT', 'GRE_ACT', 'BRX_ACT', 'SNP_ACT', 'UKI_ACT', 'OTH_ACT']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "samplesize      0.053056\n",
       "rating               1.0\n",
       "Unnamed: 0.1       102.5\n",
       "BRX_FC             1.875\n",
       "CON_FC            26.125\n",
       "GRE_FC             1.625\n",
       "LAB_FC            17.875\n",
       "LIB_FC            10.875\n",
       "OTH_FC             0.125\n",
       "SNP_FC              41.5\n",
       "OTH.1              0.125\n",
       "UKI_FC               0.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates average median value of X_test\n",
    "averages = X_test.mean()\n",
    "averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates imputation values for y_train to impute over actuals we are trying to predict\n",
    "imputation_values = {\n",
    "    'CON_ACT': averages['CON_FC'],\n",
    "    'LAB_ACT': averages['LAB_FC'],\n",
    "    'LIB_ACT': averages['LIB_FC'],\n",
    "    'BRX_ACT': averages['BRX_FC'],\n",
    "    'SNP_ACT': averages['SNP_FC'],\n",
    "    'UKI_ACT': averages['UKI_FC'],\n",
    "    'OTH_ACT': averages['OTH_FC'],\n",
    "    'GRE_ACT': averages['GRE_FC']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1297/1725420624.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y_train = y_train.fillna(value=imputation_values)\n"
     ]
    }
   ],
   "source": [
    "# Applies imputation values to y_train\n",
    "y_train = y_train.fillna(value=imputation_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 99, 8, 8)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model for each party\n",
    "models = {}\n",
    "parties = ['CON', 'LAB', 'LIB', 'BRX', 'GRE', 'SNP', 'UKI', 'OTH']\n",
    "for party in parties:\n",
    "    models[party] = XGBRegressor(\n",
    "        learning_rate=0.3, n_estimators=300, max_depth=3, subsample=0.7,\n",
    "        objective='reg:squarederror', nthread=-1, enable_categorical=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "X_train_matrix = np.array(X_train)\n",
    "for party in parties:\n",
    "    models[party].fit(X_train_matrix, y_train[f'{party}_ACT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_2019 = {\n",
    "    \"CON\": 0.251,  # Conservative Party\n",
    "    \"LAB\": 0.186,  # Labour Party\n",
    "    \"LIB\":0.95,  # Liberal Democrats\n",
    "    \"BRX\": 0.5,  # Brexit Party\n",
    "    \"GRE\": 0.01,  # Green Party\n",
    "    \"SNP\": 0.45,  # Scottish National Party\n",
    "    \"UKI\": 0.0000,  # UK Independence Party\n",
    "    \"PLC\": 0.0051,  # Plaid Cymru\n",
    "    \"OTH\": 0.0307   # Other parties\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "X_test_matrix = np.array(X_test)\n",
    "mean_predictions = {}\n",
    "for party in parties:\n",
    "    mean_predictions[party] = models[party].predict(X_test_matrix).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 mean prediction for CON: 26.163150787353516\n",
      "2019 mean prediction for LAB: 17.95258331298828\n",
      "2019 mean prediction for LIB: 10.832961082458496\n",
      "2019 mean prediction for BRX: 1.8527486324310303\n",
      "2019 mean prediction for GRE: 1.4968897104263306\n",
      "2019 mean prediction for SNP: 41.393436431884766\n",
      "2019 mean prediction for UKI: 0.0017363462829962373\n",
      "2019 mean prediction for OTH: 0.125\n"
     ]
    }
   ],
   "source": [
    "# Print mean predictions\n",
    "for party in parties:\n",
    "    print(f\"2019 mean prediction for {party}: {mean_predictions[party]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate last five polls\n",
    "last_predictions = {}\n",
    "for party in parties:\n",
    "    last_predictions[party] = models[party].predict(X_test_matrix)[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 last prediction for CON: 26.187114715576172\n",
      "2019 last prediction for LAB: 17.98794937133789\n",
      "2019 last prediction for LIB: 10.809826850891113\n",
      "2019 last prediction for BRX: 1.8414560556411743\n",
      "2019 last prediction for GRE: 1.4421885013580322\n",
      "2019 last prediction for SNP: 41.33161926269531\n",
      "2019 last prediction for UKI: 0.002801459515467286\n",
      "2019 last prediction for OTH: 0.125\n"
     ]
    }
   ],
   "source": [
    "# Print mean of predictions\n",
    "for party in parties:\n",
    "    print(f\"2019 last prediction for {party}: {last_predictions[party].mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "election_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports using Sklearn make shortcut functions\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "gcp_project_id = os.environ['GCP_PROJECT']\n",
    "gcp_service_account_key = os.environ['GCP_SERVICE_ACCOUNT_KEY']\n",
    "bq_source_dataset = os.environ['BQ_SOURCE_DATASET']\n",
    "bq_cleaned_dataset = os.environ['BQ_CLEANED_DATASET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from BQ and set data to X\n",
    "# Initialize a BigQuery client using the service account JSON file\n",
    "bq_client = bigquery.Client(project=gcp_project_id).from_service_account_json(gcp_service_account_key)\n",
    "\n",
    "# Setting the table we want from the source dataset\n",
    "select_table = 'cleaned_full_polls_combined_national_results_2004_2019'\n",
    "\n",
    "# SQL query for querying Big Query and fetching entire table\n",
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM `{gcp_project_id}.{bq_cleaned_dataset}.{select_table}`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use BQ client to create DF from the selected table\n",
    "data = bq_client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any found NaN values with 0\n",
    "data.replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a field 'poll length' that shows number of days the poll was held for\n",
    "data['poll_length'] = pd.to_datetime(data.enddate) - pd.to_datetime(data.startdate)\n",
    "data['poll_length'] = data['poll_length'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide forecasts by 100 to create values between 0-1\n",
    "for column in ['BRX_FC', 'CON_FC', 'GRE_FC', 'LAB_FC', 'LIB_FC', 'NAT_FC', 'OTH_FC', 'PLC_FC', 'SNP_FC', 'UKI_FC']:\n",
    "    data[column] = data[column] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide actuals by 100 to create values between 0-1\n",
    "for column in ['BRX_ACT', 'CON_ACT', 'GRE_ACT', 'LIB_ACT', 'LAB_ACT', 'PLC_ACT', 'SNP_ACT', 'UKI_ACT', 'OTH_PERCENTAGE']:\n",
    "    data[column] = data[column] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we don't need\n",
    "data = data.drop(columns=['startdate', 'enddate', 'pollster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle numerical transformer\n",
    "num_columns_selector = ['samplesize', 'days_to_elec', 'poll_length']\n",
    "num_transformer = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical transformer\n",
    "cat_columns_selector = ['rating']\n",
    "cat_transformer = OrdinalEncoder(categories = [['F','D-','D','D+','C-','B','B+','A-']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the preprocessing pipeline\n",
    "preproc_pipeline = make_column_transformer(\n",
    "    (num_transformer, num_columns_selector),\n",
    "    (cat_transformer, cat_columns_selector),\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit transform preprocessing pipeline to data\n",
    "data_processed = preproc_pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature names make sense\n",
    "data_processed = pd.DataFrame(\n",
    "    data_processed, columns=preproc_pipeline.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our feature matrix, by dropping irrelevant and y columns\n",
    "X = data_processed.drop(columns=['next_elec_date','NAT_ACT', 'BRX_ACT', 'CON_ACT',\n",
    "       'GRE_ACT', 'LIB_ACT', 'LAB_ACT', 'PLC_ACT', 'SNP_ACT', 'UKI_ACT',\n",
    "       'OTH_PERCENTAGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our target matrix, retaining each party share vote columns only\n",
    "y = data_processed[['LAB_ACT', 'CON_ACT', 'LIB_ACT', 'GRE_ACT', 'BRX_ACT',\n",
    "                    'NAT_ACT', 'SNP_ACT', 'UKI_ACT', 'PLC_ACT', 'OTH_PERCENTAGE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle target extraction for test and train sets respectively\n",
    "y_train_LAB = y_train['LAB_ACT']\n",
    "y_train_CON = y_train['CON_ACT']\n",
    "y_train_LIB = y_train['LIB_ACT']\n",
    "y_train_GRE = y_train['GRE_ACT']\n",
    "y_train_BRX = y_train['BRX_ACT']\n",
    "y_train_NAT = y_train['NAT_ACT']\n",
    "y_train_SNP = y_train['SNP_ACT']\n",
    "y_train_UKI = y_train['UKI_ACT']\n",
    "y_train_PLC = y_train['PLC_ACT']\n",
    "y_train_OTH = y_train['OTH_PERCENTAGE']\n",
    "\n",
    "y_test_LAB = y_test['LAB_ACT']\n",
    "y_test_CON = y_test['CON_ACT']\n",
    "y_test_LIB = y_test['LIB_ACT']\n",
    "y_test_GRE = y_test['GRE_ACT']\n",
    "y_test_BRX = y_test['BRX_ACT']\n",
    "y_test_NAT = y_test['NAT_ACT']\n",
    "y_test_SNP = y_test['SNP_ACT']\n",
    "y_test_UKI = y_test['UKI_ACT']\n",
    "y_test_PLC = y_test['PLC_ACT']\n",
    "y_test_OTH = y_test['OTH_PERCENTAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGBRegressor Model\n",
    "xgb_regression_model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model for each party\n",
    "model_LAB = xgb_regression_model\n",
    "model_CON = xgb_regression_model\n",
    "model_LIB = xgb_regression_model\n",
    "model_GRE = xgb_regression_model\n",
    "model_BRX = xgb_regression_model\n",
    "model_NAT = xgb_regression_model\n",
    "model_SNP = xgb_regression_model\n",
    "model_UKI = xgb_regression_model\n",
    "model_PLC = xgb_regression_model\n",
    "model_OTH = xgb_regression_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle model training\n",
    "model_LAB.fit(X_train, y_train_LAB)\n",
    "model_CON.fit(X_train, y_train_CON)\n",
    "model_LIB.fit(X_train, y_train_LIB)\n",
    "model_GRE.fit(X_train, y_train_GRE)\n",
    "model_BRX.fit(X_train, y_train_BRX)\n",
    "model_NAT.fit(X_train, y_train_NAT)\n",
    "model_SNP.fit(X_train, y_train_SNP)\n",
    "model_UKI.fit(X_train, y_train_UKI)\n",
    "model_PLC.fit(X_train, y_train_PLC)\n",
    "model_OTH.fit(X_train, y_train_OTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oscar/.pyenv/versions/3.10.6/envs/election_predictor/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [08:58:56] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/oscar/.pyenv/versions/3.10.6/envs/election_predictor/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [08:58:56] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/oscar/.pyenv/versions/3.10.6/envs/election_predictor/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [08:58:56] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/oscar/.pyenv/versions/3.10.6/envs/election_predictor/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [08:58:57] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/oscar/.pyenv/versions/3.10.6/envs/election_predictor/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [08:58:57] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgboost = XGBRegressor(learning_rate=0.3, n_estimators=1000,\n",
    "                                     max_depth=3, subsample=0.7,\n",
    "                                     objective='reg:linear', nthread=-1,\n",
    "                                     )\n",
    "\n",
    "# Score of the model\n",
    "LAB_score = cross_val_score(xgboost,np.array(X),y_LAB, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "election_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
